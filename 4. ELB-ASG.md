# 1. Elastic Load Balancer(ELB)
 ## * Scalability 
 Scalability means that your application system can hinder a greater load by adapting. And so, there are two kind of scalability.

  1. **Vertical scalability**  
  that means that you need to increase the size of your instance.

      So, let's take a phone operator, for example. We have a junior operator and we just hired him.  He's great but he can only take five calls per minute. Now, we have a senior operator and he's much greater. He can take up to ten calls per minute. So, we've basically scaled up our junior operator into senior operator and he's faster and better.   
      ![Vertical-scalibility](/images/VERTiCAL-SCALE.png "VS")

      So, for example, in EC2, our application runs on a a t2.micro and we want to upscale that application,that means we want to run it on a t2.large

      So, when do we use vertical scalability?
      Well, it's very common when you have non distributed system, such as a data base.
      So, it's quite common for a data base, for example, on RDS or ElastiCache, these are services that you can just scale vertically by upgrading the underlying instance type, although, there usually are limits to how much you can vertically scale and that's a hardware limit but still, vertical scalability is fine for a lot of use cases.

  2.  **Horizontal scalability, also called elasticity.**  
      Horizontal scalability means that you increases the number of instances/systems for your application.

      So, let's take again, our call center. We have an operator and he is being overloaded. I don't want to vertically scale it, I want to hire a second operator and now, I've just doubled my capacity. Actually, I'll hire a third operator.   
      ![Vertical-scalibility](/images/HORIZONTAL-SCALE.png "VS")

  3.  **High Availibility**   
    High availability, that means that you're running your application or system in at least two data centers, or two availability zones in AWS. And he goal of high availability is to be able to survive a data center loss, so in case one center goes down, then we're still running.  
    ![Highly-availibity](/images/HIGHLY-AVAILABLE.png "HA")

## * Elastic Load Balancing(ELB)
 Load balancers are servers that will forward internet traffic to your multiple backhand EC2 Instances.
![ELB](/images/ELASTIC-LOAD-BALANCING.png "ELB")
### Why use a load balancer?
  * Spread load across multiple downstream instances 
  * Expose a single point of access (DNS) to your application 
  * Seamlessly handle failures of downstream instances 
  * Do regular health checks to your instances 
  * Provide SSL termination (HTTPS) for your websites 
  * Enforce stickiness with cookies 
  * High availability across zones 
  * Separate public traffic from private traffic
### Why use an EC2 Load Balancer?
  * An ELB (EC2 Load Balancer) is a managed load balancer
    * AWS guarantees that it will be working
    * AWS takes care of upgrades, maintenance, high availability
    * AWS provides only a few configuration knobs
  * It costs less to setup your own load balancer but it will be a lot more effort on your end. 
  * It is integrated with many AWS offerings / services
### Health Checks
  * Health Checks are crucial for Load Balancers
  * They enable the load balancer to know if instances it forwards traffic to are available to reply to requests
  * The health check is done on a port and a route (/health is common)
  * If the response is not 200 (OK), then the instance is unhealthy
### Health Checks
AWS has **3** kinds of managed Load Balancers
* Classic Load Balancer (v1 - old generation) – 2009
  * Supports HTTP, HTTPS, TCP
* Application Load Balancer (v2 - new generation) – 2016
  * Supports HTTP, HTTPS, WebSocket to
*  Network Load Balancer (v2 - new generation) – 2017
   * Supports TCP, TLS (secure TCP) & UDP to
* Overall, it is recommended to use the newer / v2 generation load balancers as they provide more features 
* If the LB can’t connect to your application, check your security groups!
* Load Balancer Errors 503 means at capacity or no registered target
### Load Balancer Security Groups
the more interesting part is between the load balancers and your EC2 instance. So, there is going to be HTTP traffic between these two because your load balancer has to talk to your EC2 instances through HTTP, but this time, we want that traffic to be strictly restricted to your load balancer. What that means is that your EC2 instance expects only your load balancer to send traffic to it. And as such, we can have an application security group which allows only traffic from the load balancer. And so here, the interesting this is that it says, okay, HTTP on Port 80, the source of which is a security group, you see there is a long security group with an ID.
And, that security group ID represents the load balancer security group ID. So, the load balancer here has a security group. Your EC2 instance has a security group. The EC2 instance security group references the one
from the load balancer, which is right here, and the line from the load balancer has the rules which allows the users to access from anywhere on HTTP and HTTPS. That is the most secure one
![ELB-SC](/images/LOAD_BALANCER-SECURITY_GROUPS.png "ELB-SC")

## 1. Classic Load Balancer(ELB)
So they support two things, the TCP or traffic or HTTP and HTTPS. So the health checks are either TCP based or HTTP based. 
What we are going to
* create Load Balancer -> choose Classic Load balancer and just give the name
* then create new security group will lead Load balancer. if you want just your load balacer talk instance you need to create Security group and that SC will restrict EC2 just speak load balancer.
* then we are going to create health check. and we are going to play maybe on threshold=5, ping path =/
* and then we are going to choose an instance 
* then next and create it.
* so if you go description and copy DNS name and go to browser you should see same result with ip call
* so here the problem we just wanted our load balancer access our EC2 lets solve that
* the problem you need to check your security-groups and find inbound http just come from load-balancer's security group
* so here we can create more instances and assign our Classic load balancer and then load balancer will spread traffic on instances. when you see status inService then it works
* then lets delete clb
## 2. Application Load Balancer(ELB)
* Application load balancers is Layer 7 (HTTP)
* Load balancing to multiple HTTP applications across machines (target groups)
* Load balancing to multiple applications on the same machine (ex: containers)
* Support for HTTP/2 and WebSocket
* Support redirects (from HTTP to HTTPS for example)
* Routing tables to different target groups
  * Routing based on path in URL (example.com/users & example.com/posts)
  * Routing based on hostname in URL (one.example.com & other.example.com)
  * Routing based on Query String, Headers (example.com/users?id=123&order=false)
* ALB are a great fit for micro services & container-based application (example: Docker & Amazon ECS) 
* Has a port mapping feature to redirect to a dynamic port in ECS
* In comparison, we’d need multiple Classic Load Balancer per application
 ![APPL-LB](/images/APPL-LOAD-BALANCER.png "APPL-LB")
* EC2 instances (can be managed by an Auto Scaling Group) – HTTP 
* Lambda functions – HTTP request is translated into a JSON event
* IP Addresses – must be private IPs
* ALB can route to multiple target groups
* Health checks are at the target group level
* The application servers don’t see the IP of the client directly
  * The true IP of the client is inserted in the header X-Forwarded-For
  * We can also get Port (X-Forwarded-Port) and proto (X-Forwarded-Proto)
* so we are going to create ALB from Load Balancers
* choose your Availibility zones and continue 
* and choose your security group 
* and choose your target-group under the routing tab and choose instance and here you go
* then after ALB be active you will get 503 error
* because we didnt register and instnace to target-group
* in the left menu after load-balancers you will see Target-Groups 
* and go there choose your target groups andtry to add instance
* and now when you go your dns address it will work
* now we are going to do path forwarded to EC2 instances
* so if we click /user will go x instance /product will go y instance /order will go z instance
* for that we are going to create new target-groups
* after that goto load-balancer listeners tab and view-edit rules
* and click add new choose path /orders and forward to orders-target-group
* or you can create other rules example /groups forwreturn fix response 404 not found
## 3. Network Load Balancer(NLB)
They're layer four load balancers, that means that they allow you to forward TCP or UDP based traffic to your instances, so it's lower level. 
* It allows you to handle millions of requests per second, so they're extremely high performance
* the latency is a lot less than for the ALB.  
* They expose one static IP per availability zone on the outside, and that is very helpful when you want to white list specific IP. And also, they support assigning elastic IPs instead of getting the ones given by the NLB itself. So that means that you can use NLB when you want you have two entry points, for example, that are dedicated specific IP for your application, and then the NLB will forward that traffic into your EC2 instances.
 ![APPL-LB](/images/NETWORK-LOAD-BALANCER.png "APPL-LB") 
 1. go to load balancers try to create network load balancer
 2. as you cansee you can just choose TCP,TLS,UDP protocols
 3. choose your zones and you can assign Elastic IP but not for now because it charge money
 4. then create a target group
 5. choose the instances and create
 6. you will see you cannot reach anything from dns address because your instance security group doesnt allow TCP protocol from 80 port
 7. we need to open security group and  add TCP 80 port
 8. yes now it should work
## 4. Load balancers Stickness
Stickiness is very helpful if you want the same request originating from the same client, to go to the same target
* It is possible to implement stickiness so that the same client is always redirected to the same instance behind a load balancer
* This works for Classic Load Balancers & Application Load Balancers
* The “cookie” used for stickiness has an expiration date you control
 ![APPL-LB](/images/LOAD-BALANCER-STICKNESS.png "APPL-LB") 
 1. got your target groups under gtoup details you will find attributes try to edit
 2. and you will see after after refresh for 300 seconds it will always show one instance
 3. then after cookie die it will release stickness
 ## 5. Cross Zone Balancing
 * With Cross Zone Load Balancing: each load balancer instance distributes evenly across all registered instances in all AZ
 * Otherwise, each load balancer node distributes requests evenly across the registered instances in its Availability Zone only
  ![APPL-LB](/images/CROSS-LOAD-BALANCER.png "APPL-LB") 
 1. Classic Load Balancer  
     * Disabled by default
     *  No charges for inter AZ data if enabled
 2.  Application Load Balancer
     * Always on (can’t be disabled)
     * No charges for inter AZ data 
 3.  Network Load Balancer
     * Disabled by default 
     * You pay charges ($) for inter AZ data if enabled
* Go your load balncer in the attributes side you will see cross-load-balancer choice
* for classic you can enable, in the application there is not any choice always enabled in the network you can enable but it will warn you about money
 ## 5. SSL/TLS Basic
 * An SSL Certificate allows traffic between your clients and your load balancer to be encrypted in transit (in-flight encryption)
 * SSL refers to Secure Sockets Layer, used to encrypt connections
 * TLS refers to Transport Layer Security, which is a newer version
 * Public SSL certificates are issued by Certificate Authorities (CA); Comodo,Symantec,Godaddy...
 * SSL certificates have an expiration date (you set) and must be renewed
 ### Load Balancer - SSL Certificates
 ![APPL-LB](/images/SSL-LOAD-BALANCER.png "APPL-LB") 
 * The load balancer uses an X.509 certificate
 * You can manage certificates using ACM
 * You can create upload your own certificates alternatively
 * Https Listener
   * You must specify a default certificate
   * You can add an optional list of certs to support multiple domains
   * **Clients can use SNI (Server Name Indication) to specify the hostname they reach**
   * Ability to specify a security policy to support older versions of SSL / TLS (legacy clients)

 ### SSL -Server Name indication
  using SNI or a server name indication, you are able to have multiple target groups for different websites using different SSL certificates.
  * SNI solves the problem of loading multiple SSL certificates onto one web server (to serve multiple websites)
  * It’s a “newer” protocol, and requires the client to indicate the hostname of the target server in the initial SSL handshake
  * Only works for ALB & NLB (newer generation), CloudFront
 ### Elastic Load Balancers – SSL Certificates
 * Classic Load Balancer (v1)
    * Support only one SSL certificate
    * Must use multiple CLB for multiple hostname with multiple SSL certificates
 * Application Load Balancer (v2)
    * Supports multiple listeners with multiple SSL certificates
    * Uses Server Name Indication (SNI) to make it work
 * Network Load Balancer (v2)
    * Supports multiple listeners with multiple SSL certificates
    * Uses Server Name Indication (SNI) to make it work
1. Goto Classic load balancer listener tab and edit it add Https listener and choose a cipher
2. for Applocation Load baalancer is it same goto listener part add Https listener here there is
  target groups. in ALS you are going to choose SSL for each target group you can use different SSLs for each TG. 
3. in Network Load baalncer we are going to choose TLS/443 because it doesnt http
 ### **Connection Draining**
 Our first EC2 instance through the ELB. It turns out that our EC2 instance maybe is being terminated or is unhealthy so it's gonna go into draining mode.
* CLB: Connection Draining
* Target Group: Deregistration Delay (for ALB & NLB)
* Time to complete “in-flight requests” while the instance is de-registering or unhealthy
* Stops sending new requests to the instance which is de-registering
## 6. Auto Scaling Groups
* In real-life, the load on your websites and application can change
* In the cloud, you can create and get rid of servers very quickly
### The goal of an Auto Scaling Group (ASG) is to
* Scale out (add EC2 instances) to match an increased load
* Scale in (remove EC2 instances) to match a decreased load
* Ensure we have a minimum and a maximum number of machines running
* Automatically Register new instances to a load balancer
1. minimum size : for example at least 1 instance should work
2. desired size : in normal conditions 3 instance should work. so that is the actual instance size
3. Mazimum size : (scale out) in very heavy internet traffic increase instance size 20 for example
            
            scale in needed< -----desired capacity------>scale out needed

if we add EC2 instances then the Load Balancer will also register its targets, obviously perform health checks, and directly reach traffic back to them. So Load Balancer and Auto Scaling Group really work hand in hand in AWS. they are worling together and Load balancer say ASG to scale in or scale out instance size because LB handle all internet traffic.

### ASGs have the following attributes
* A launch configuration
  * AMI + Instance Type, EC2 User Data, EBS Volumes, Security Groups, SSH Key Pair
* Min Size / Max Size / Initial Capacity
* Network + Subnets Information
* Load Balancer Information
* Scaling Policies
### Auto Scaling Alarms
* It is possible to scale an ASG based on CloudWatch alarms
* An Alarm monitors a metric (such as Average CPU)
* Metrics are computed for the overall ASG instances
* We can create scale-out policies (increase the number of instances)
* We can create scale-in policies (decrease the number of instances)
### Auto Scaling New Rules 
* Target Average CPU Usage
* Number of requests on the ELB per instance
* Average Network In
* Average Network Out
### Auto Scaling Custom Metric
* We can auto scale based on a custom metric (ex: number of connected users)
* Send custom metric from application on EC2 to CloudWatch(PutMetric API)
*  Create CloudWatch alarm to react to low / high values
*  Use the CloudWatch alarm as the scaling policy for ASG
### **ASG Brain Dump**
* Scaling policies can be on CPU, Network… and can even be on custom metrics or based on a schedule (if you know your visitors patterns)
* ASGs use Launch configurations or Launch Templates (newer) 
* To update an ASG, you must provide a new launch configuration / launch template
* IAM roles attached to an ASG will get assigned to EC2 instances
* ASG are free. You pay for the underlying resources being launched
* Having instances under an ASG means that if they get terminated for whatever reason, the ASG will automatically create new ones as a replacement. Extra safety!
* ASG can terminate instances marked as unhealthy by an LB (and hence replace them) 
### To hands on
* goto Auto scaling group from left menu
* then we are going to create Launch template
* choose your AMI EC2 machine Amazon Linux 2 AMI
* choose your instance type t2.nano
* choose key pair
* choose network setting VPC
* choose your security group
* skip volume,tag,network interface
* and in advanced add your user data
* the click create launch template
* and then goto ASG tab back
* choose the template we created and click next
* choose the sunets Availibility zones
* and then choose the Load balancing
* and choose target group for load balancer and next
* and here choose min, max, desired instances size
* and next next create auto scale group
* and now go to your target groups assign instances and copy dns name of load balancer will show result in browser
* you can scale in or scale out with increase and decrease desired size
### Auto Scaling Groups – Scaling Policies
* Target Tracking Scaling
  * Most simple and easy to set-up
  * Example: I want the average ASG CPU to stay at around 40%
* Simple / Step Scaling
  * When a CloudWatch alarm is triggered (example CPU > 70%), then add 2 units
  * When a CloudWatch alarm is triggered (example CPU < 30%), then remove 1
* Scheduled Actions
  * Anticipate a scaling based on known usage patterns
  * Example: increase the min capacity to 10 at 5 pm on Fridays

for example when you create Target tracking scaling from Auto Scaling Group  Auto scale part
and it can reduce your desired capacity automaticly becuase you are not using alot of cpu

